<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>pytorch | 洁莹不吃鱼</title><meta name="author" content="洁莹不吃鱼"><meta name="copyright" content="洁莹不吃鱼"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="pytorch框架学习">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch">
<meta property="og:url" content="https://6jybuchiyu.github.io/2023/01/09/pytorch/index.html">
<meta property="og:site_name" content="洁莹不吃鱼">
<meta property="og:description" content="pytorch框架学习">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://6jybuchiyu.github.io/img/blogset/2.jpg">
<meta property="article:published_time" content="2023-01-08T23:47:47.000Z">
<meta property="article:modified_time" content="2023-01-14T04:48:02.641Z">
<meta property="article:author" content="洁莹不吃鱼">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="框架">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://6jybuchiyu.github.io/img/blogset/2.jpg"><link rel="shortcut icon" href="/../img/blogset/9.jpg"><link rel="canonical" href="https://6jybuchiyu.github.io/2023/01/09/pytorch/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"简","msgToSimplifiedChinese":"繁"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'pytorch',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-01-14 12:48:02'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/blogset/9.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">6</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/./img/blogset/2.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">洁莹不吃鱼</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">pytorch</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-01-08T23:47:47.000Z" title="发表于 2023-01-09 07:47:47">2023-01-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-01-14T04:48:02.641Z" title="更新于 2023-01-14 12:48:02">2023-01-14</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">7.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>34分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="pytorch"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>创建新项目的时候选择的编译器要选择Conda环境，如果手选Conda环境，要在Anaconda3的envs这个文件里选pytorch里面的python.exe就可以了。</p>
<h1 id="两个重要函数"><a href="#两个重要函数" class="headerlink" title="两个重要函数"></a>两个重要函数</h1><p>pytorch是一个package工具箱</p>
<ul>
<li><code>dir()</code>:打开，看见里面有什么东西。当使用dir()得到的参数是双下划线的时候，说明这些标识符是函数。</li>
<li><code>help()</code>：说明书，还有一种形式例如<code>Dataset??</code><ul>
<li>例如查看<code>is_available()</code>函数，我们就运行<code>help(torch.cuda.is_available)</code>，括号里只需要输入标识符即可</li>
</ul>
</li>
</ul>
<h1 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h1><p>如何读取数据涉及到两个类</p>
<ul>
<li>Dataset：提供一种方式去获取数据及其label。<ul>
<li>Dataset是一个抽象类，所有数据集都要继承它，所有子类都要实现<code>getitem</code>方法，选择性重写<code>len</code>方法。</li>
<li>如何获取每一个数据及其label？实现<code>getitem</code>方法。</li>
<li>告诉我们总共有多少的数据？重写<code>len</code>方法</li>
</ul>
</li>
<li>Dataloader：对我们要送进网络的数据进行打包，为网络提供不同的数据形式</li>
</ul>
<p><strong>import os</strong>:</p>
<ul>
<li><p><code>os.path.join(str1,str2...)</code>函数的参数可以放字符串，得到的字符串结果是把多个字符串用<code>\\</code>连接，因为单独的\会被当成转义字符，&#x2F;并不是转义字符，例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">root_dir=<span class="string">&quot;dataset/train&quot;</span>	label_dir=<span class="string">&quot;ants&quot;</span></span><br><span class="line">path=os.path.join(root_dir,label_dir)</span><br><span class="line">&gt;&gt;&gt;path=&#123;<span class="built_in">str</span>&#125;<span class="string">&#x27;dataset/train\\ants&#x27;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>os.listdir(path)</code>函数可以将路径path中的文件转化成列表形式，例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img_path_list=os.listdir(path)</span><br><span class="line">&gt;&gt;&gt;img_path_list=&#123;<span class="built_in">list</span>:<span class="number">124</span>&#125;[...]</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>from PIL import Image</strong>：</p>
<ul>
<li><code>Image.open(img_path)</code>此函数用于创建图片，返回<code>&#123;JpegImageFile&#125;</code>变量</li>
<li><code>img.show()</code>函数用于显示图片</li>
</ul>
<p>对目前所学的一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="comment"># 从常用工具区的关于数据的 data 区 import Dataset</span></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image  <span class="comment">#读取图片</span></span><br><span class="line"><span class="keyword">import</span> os <span class="comment">#operating system 关于系统的库</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyData</span>(<span class="title class_ inherited__">Dataset</span>):<span class="comment">#继承Dataset类</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,root_dir,label_dir</span>):</span><br><span class="line">        self.root_dir=root_dir  <span class="comment">#self相当于在类中创建了全局变量</span></span><br><span class="line">        self.label_dir=label_dir</span><br><span class="line">        self.path = os.path.join(self.root_dir, self.label_dir)</span><br><span class="line">        self.img_path = os.listdir(self.path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        img_name = self.img_path[idx]<span class="comment">#注意要加self</span></span><br><span class="line">        img_item_path = os.path.join(self.path,img_name)</span><br><span class="line">        img=Image.<span class="built_in">open</span>(img_item_path)</span><br><span class="line">        label = self.label_dir <span class="comment">#相对于本个例子而言的label</span></span><br><span class="line">        <span class="keyword">return</span> img, label</span><br><span class="line">    <span class="comment">#这里重写了getitem，返回img，label，就达到了我们利用下标获取每一个数据及其label的目的</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.img_path)<span class="comment">#返回列表长度</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root_dir = <span class="string">&quot;dataset/train&quot;</span></span><br><span class="line"></span><br><span class="line">ants_label_dir = <span class="string">&quot;ants&quot;</span></span><br><span class="line">ants_dataset = MyData(root_dir, ants_label_dir)</span><br><span class="line"></span><br><span class="line">bees_label_dir = <span class="string">&quot;bees&quot;</span></span><br><span class="line">bees_dataset = MyData(root_dir, bees_label_dir)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ants_dataset[<span class="number">0</span>])<span class="comment">#会输出img以及对应的label</span></span><br><span class="line">img,label = ants_dataset[<span class="number">0</span>]<span class="comment">#实现了geititem函数，有两个返回值</span></span><br><span class="line">img.show()//显示图片</span><br><span class="line">img,label = bees_dataset[<span class="number">1</span>]</span><br><span class="line">img.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">len</span>(ants_dataset)<span class="comment">#得到124</span></span><br><span class="line"><span class="built_in">len</span>(bees_dataset)<span class="comment">#得到121</span></span><br><span class="line">train_dataset = ants_dataset+bees_dataset<span class="comment">#这个数据集会变成ants_dataset和bees_dataset的拼接，达到仿造数据集，解决数据集不足问题</span></span><br><span class="line"><span class="built_in">len</span>(train_dataset)<span class="comment">#得到245</span></span><br><span class="line"></span><br><span class="line">img,label=train_dataset[<span class="number">123</span>]<span class="comment">#得到蚂蚁，蚂蚁是[0-123]</span></span><br><span class="line">img,label=train_dataset[<span class="number">124</span>]<span class="comment">#得到蜜蜂，蜜蜂是[124-244]</span></span><br></pre></td></tr></table></figure>



<p>作出数据集的另一种存储方式：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#把图片的label生成以图片名为文件名的txt文档</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">root_dir = <span class="string">&#x27;练手数据集/train&#x27;</span></span><br><span class="line">target_dir = <span class="string">&#x27;ants_image&#x27;</span></span><br><span class="line">img_path = os.listdir(os.path.join(root_dir, target_dir))</span><br><span class="line">label = target_dir.split(<span class="string">&#x27;_&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">out_dir = <span class="string">&#x27;ants_label&#x27;</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> img_path:</span><br><span class="line">    file_name = i.split(<span class="string">&#x27;.jpg&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(root_dir, out_dir,<span class="string">&quot;&#123;&#125;.txt&quot;</span>.<span class="built_in">format</span>(file_name)),<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:<span class="comment">#open会生成不存在的文件</span></span><br><span class="line">        f.write(label)</span><br></pre></td></tr></table></figure>



<h1 id="TensorBoard的使用"><a href="#TensorBoard的使用" class="headerlink" title="TensorBoard的使用"></a>TensorBoard的使用</h1><p>TensorBoard：演示transform的结果，在运行完方法后展示图像。例如loss图、训练结果output。</p>
<p>首先要<code>from torch.utils.tensorboard import SummaryWriter</code>。</p>
<h2 id="SummaryWriter类使用"><a href="#SummaryWriter类使用" class="headerlink" title="SummaryWriter类使用"></a>SummaryWriter类使用</h2><p><code>CTRL</code>+鼠标移至类可以查看类的用法。</p>
<ul>
<li><p>SummerWriter将条目直接写入 TensorBoard 要使用的<code>log_dir</code>中的事件文件，事件文件可以直接被TensorBoard解析。</p>
</li>
<li><p>初始化的时候需要输入<code>log_dir</code>文件夹的名称，不输入也可以，有默认位置。</p>
</li>
<li><p>初始化方式：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">writer = SummaryWriter()<span class="comment">#什么都不加，默认的事件文件存储的位置在runs/下</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;my_experiment&quot;</span>)<span class="comment">#给出初始化文件夹</span></span><br><span class="line">writer = SummaryWriter(comment=<span class="string">&quot;LR_0.1_BATCH_16&quot;</span>)<span class="comment">#设置相应参数</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p>主要用到两个方法：</p>
<ul>
<li><code>writer.add_scalar(tag(string),scalar_value(float or string/blobname),global_step(int))</code><ul>
<li>参数<code>tag(string)</code>设置图表的title</li>
<li>参数<code>scalar_value(float or string/blobname)</code>设置图表y轴</li>
<li>参数<code>global_step(int)</code>对应x轴</li>
</ul>
</li>
</ul>
<p>打开事件文件，在pycharm的命令行，输入<code>tensorboard --logdir=事件文件所在文件夹名</code>。如果端口被占用了，可以自行添加端口，输入<code>tensorboard --logdir=事件文件所在文件夹名 --port=端口值  </code> </p>
<p>如果打开的tensorboard出现了重复在一张图上的情况，需要进行删除原来的事件文件，或者重新SummaryWriter一个<code>log_dir</code>文件</p>
<ul>
<li><code>writer.add_image(tag(string),img_tensor(torch.Tensor, numpy.array, or string/blobname),global_step(int))</code><ul>
<li>参数<code>tag(string)</code>，设置图像的title</li>
<li>参数<code>img_tensor(torch.Tensor, numpy.array, or string/blobname)</code>，设置图像</li>
<li>参数<code>global_step(int)</code>，设置训练步骤</li>
</ul>
</li>
</ul>
<p>可以利用Opencv读取图片，获得numpy型图片数据。</p>
<p>如果是用PIL数据转化成numpy数据，需要在add_image()中指定shape中每一个数字&#x2F;维表示的含义。主要是通道数。</p>
<p>step可以理解为多张图片可以放在同一个title里面，通过滑块可以看到每一步的图片，如果想让多张图片单独显示，需要把title重新命名</p>
<p>上面的代码综合运用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)<span class="comment">#存储文件夹</span></span><br><span class="line"><span class="comment"># y=3x</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>): <span class="comment">#i从0-99</span></span><br><span class="line">    writer.add_scalar(<span class="string">&quot;y=3x&quot;</span>,<span class="number">3</span>*i,i)<span class="comment"># 添加标量</span></span><br><span class="line"></span><br><span class="line">img_path = <span class="string">&quot;data/train/ants_image/0013035.jpg&quot;</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">img_array = np.array(img)   <span class="comment"># 类型转换，这样得到的numpy.array的通道是在最后面的</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(img_array))</span><br><span class="line"><span class="built_in">print</span>(img_array.shape)      <span class="comment"># 结果是(512,768,3)</span></span><br><span class="line">writer.add_image(<span class="string">&quot;train&quot;</span>,img_array,<span class="number">1</span>,dataformats=<span class="string">&#x27;HWC&#x27;</span>)<span class="comment">#需要指定是HWC型，因为数据就是通道在最后面，不然会报错</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>



<h1 id="Transforms的使用"><a href="#Transforms的使用" class="headerlink" title="Transforms的使用"></a>Transforms的使用</h1><p>Transforms主要是用于对图片进行一些变换。将特定格式的图片经过工具之后输出我们想要的图片结果。</p>
<h2 id="Transforms的结构及用法"><a href="#Transforms的结构及用法" class="headerlink" title="Transforms的结构及用法"></a>Transforms的结构及用法</h2><p>Transforms.py工具箱具有的工具：</p>
<ul>
<li>Totensor类，Totensor就是把PIL Image或者numpy.ndarray类型转化为tensor类型的</li>
<li>resize类，裁剪</li>
<li>…</li>
</ul>
<h2 id="tensor数据类型"><a href="#tensor数据类型" class="headerlink" title="tensor数据类型"></a>tensor数据类型</h2><p>通过transforms.Totensor去解决两个问题：</p>
<ul>
<li><p>transforms该如何使用(python)？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensor_trans = transforms.ToTensor() 	<span class="comment">#返回totensor的对象，默认构造</span></span><br><span class="line">tensor_img = tensor_trans(img)			<span class="comment">#将img转化为tensor类型的img</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Tensor数据类型相较于普通的数据类型或者图片数据类型有何区别？为什么需要tensor的数据类型？</p>
<p>Tensor数据类型包装了神经网络所需要的一些参数</p>
</li>
</ul>
<p>上述示例代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">img_path = <span class="string">&quot;data/train/ants_image/0013035.jpg&quot;</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line"><span class="built_in">print</span>(img) <span class="comment"># 得到&lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=768x512 at 0x1B1C3BB77F0&gt;</span></span><br><span class="line"></span><br><span class="line">tensor_trans = transforms.ToTensor() <span class="comment">#新建totensor的对象</span></span><br><span class="line">tensor_img = tensor_trans(img)<span class="comment">#调用call函数，调用类的名称时会自动运行该方法，将img转化为tensor类型的img</span></span><br><span class="line"><span class="built_in">print</span>(tensor_img)</span><br><span class="line"></span><br><span class="line">cv_img = cv2.imread(img_path) <span class="comment">#cv_img的数据类型就是numpy.ndarray</span></span><br><span class="line">tensor_cv_img = tensor_trans(cv_img)<span class="comment">#将cv_img转化为tensor类型的img</span></span><br><span class="line"><span class="built_in">print</span>(tensor_cv_img)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line">writer.add_image(<span class="string">&quot;Tensor_img&quot;</span>,tensor_img)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p>python中call函数的作用：call函数可以直接使用<code>对象名(参数)</code>这种方式去调用，这种方式就像Java重写的toString一样</p>
<h2 id="常见的Transform"><a href="#常见的Transform" class="headerlink" title="常见的Transform"></a>常见的Transform</h2><p>Compose类：把不同的transform结合在一起</p>
<p>ToTensor类：把PIL Image或者numpy.ndarray类型转化为tensor类型</p>
<p>ToPILImage类：把tensor类型或者ndarray类型转化为PIL Image类型</p>
<p>Normalize类：用平均值和标准差对tensor image(图像张量)进行归一化，归一到[-1,1]</p>
<p>Resize类：把图像缩放成指定的大小，如果给了元组序列，图像就会按元组序列的大小来重新调整，如果只是给了一个int型，图像就会以这个int型进行等比缩放，最短边的长度等于int值。输入为PIL Image，返回值还是PIL Image</p>
<p>RandomCrop类：随即裁剪，和Resize用法差不多，输入都是 PIL Image</p>
<p>使用方法总结：1. 关注输入和输出类型，输出可以直接print()看，也可以断点看 2.多看官方文档 3.关注方法需要的参数，没有设置默认值就是要输入的参数，找到它然后查看它的类型</p>
<p>上述代码实例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&quot;data/train/ants_image/0013035.jpg&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(img)</span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Totensor</span></span><br><span class="line">trans_totensor = transforms.ToTensor()</span><br><span class="line">img_tenser = trans_totensor(img)</span><br><span class="line">writer.add_image(<span class="string">&quot;ToTenser&quot;</span>, img_tenser)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize</span></span><br><span class="line"><span class="comment"># 归一化计算公式：output[channel] = (input[channel] - mean[channel]) / std[channel]</span></span><br><span class="line"><span class="built_in">print</span>(img_tenser[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">trans_norm = transforms.Normalize([<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>],[<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>])</span><br><span class="line">img_norm = trans_norm(img_tenser)</span><br><span class="line"><span class="built_in">print</span>(img_norm[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">writer.add_image(<span class="string">&quot;Normalize&quot;</span>,img_norm)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Resize</span></span><br><span class="line"><span class="built_in">print</span>(img.size) <span class="comment">#(768, 512)</span></span><br><span class="line">trans_resize = transforms.Resize((<span class="number">512</span>,<span class="number">512</span>))</span><br><span class="line"><span class="comment"># img是PIL类型，经过resize返回还是一个PIL类型</span></span><br><span class="line">img_resize = trans_resize(img)</span><br><span class="line"><span class="built_in">print</span>(img_resize)   <span class="comment">#&lt;PIL.Image.Image image mode=RGB size=512x512 at 0x13442E71430&gt;</span></span><br><span class="line"><span class="comment">#img_resize.show()</span></span><br><span class="line"><span class="comment"># PIL类型使用totensor转化为tensor对象</span></span><br><span class="line">img_resize = trans_totensor(img_resize)</span><br><span class="line">writer.add_image(<span class="string">&quot;Resize&quot;</span>,img_resize,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compose — resize的第二种用法</span></span><br><span class="line">trans_resize_2 = transforms.Resize(<span class="number">512</span>)</span><br><span class="line"><span class="comment"># PIL Image-&gt;PIL Image-&gt;tensor 要注意列表中前一个输出和后一个输入是不是相互匹配，因为是联系的</span></span><br><span class="line">trans_compose = transforms.Compose([trans_resize_2,trans_totensor])</span><br><span class="line">img_resize_2 = trans_compose(img)<span class="comment">#第一个transform需要的输入</span></span><br><span class="line">writer.add_image(<span class="string">&quot;Resize&quot;</span>,img_resize_2,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># RandomCrop</span></span><br><span class="line">trans_random = transforms.RandomCrop(<span class="number">512</span>)</span><br><span class="line">trans_compose_2 = transforms.Compose([trans_random,trans_totensor])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    img_crop = trans_compose_2(img)</span><br><span class="line">    writer.add_image(<span class="string">&quot;RandomCrop&quot;</span>,img_crop,i)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>





<h1 id="将dataset和transform结合到一起"><a href="#将dataset和transform结合到一起" class="headerlink" title="将dataset和transform结合到一起"></a>将dataset和transform结合到一起</h1><p>dataset告诉我们数据集在什么样的位置和多少数据，给索引＋数据</p>
<p>具体实例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset_transform = torchvision.transforms.Compose([</span><br><span class="line">    torchvision.transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 保存数据集的路径，训练集还是测试集，transform，下载到本地否，&#x27;.&#x27;表示当前目录,&#x27;..&#x27;表示上一级目录</span></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&quot;./dataset&quot;</span>,train=<span class="literal">True</span>,transform=dataset_transform,download=<span class="literal">True</span>)<span class="comment">#训练集</span></span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">&quot;./dataset&quot;</span>,train=<span class="literal">False</span>,transform=dataset_transform,download=<span class="literal">True</span>)<span class="comment">#测试集</span></span><br><span class="line"><span class="comment"># (&lt;PIL.Image.Image image mode=RGB size=32x32 at 0x2784D869610&gt;, 3),3是target</span></span><br><span class="line"><span class="comment"># 原始图片是PIL Image</span></span><br><span class="line"><span class="built_in">print</span>(test_set[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(test_set.classes)</span><br><span class="line"></span><br><span class="line">img, target = test_set[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(img)</span><br><span class="line"><span class="built_in">print</span>(target)</span><br><span class="line"><span class="built_in">print</span>(test_set.classes[target])</span><br><span class="line">img.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(test_set[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    img,target = test_set[i]</span><br><span class="line">    writer.add_image(<span class="string">&quot;test_set&quot;</span>,img,i)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>



<h1 id="dataloader"><a href="#dataloader" class="headerlink" title="dataloader"></a>dataloader</h1><p>dataloader就是从dataset中取数据，参数控制取多少怎么取</p>
<ul>
<li>batch_size这个参数是指每次取多少数据</li>
<li>suffle这个参数是打乱顺序</li>
<li>num_workers多线程，加载数据的时候采用单个线程还是多个线程，默认情况为0，采用主线程</li>
<li>drop_last是否舍去最后的余数</li>
</ul>
<p>代码实例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备的测试数据集</span></span><br><span class="line">test_data = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor())</span><br><span class="line"></span><br><span class="line"><span class="comment">#取出四个img，四个target的形式分别打包返回</span></span><br><span class="line">test_loader = DataLoader(dataset=test_data,batch_size=<span class="number">64</span>,shuffle=<span class="literal">False</span>,num_workers=<span class="number">0</span>,drop_last=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试数据集中第一张图片及target</span></span><br><span class="line">img,target = test_data[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(img.shape)</span><br><span class="line"><span class="built_in">print</span>(target)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):<span class="comment">#相当于一轮结束的洗牌</span></span><br><span class="line">    step = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">        imgs, targets = data</span><br><span class="line">        <span class="comment"># print(imgs.shape)</span></span><br><span class="line">        <span class="comment"># print(targets)</span></span><br><span class="line">        writer.add_images(<span class="string">&quot;Epoch:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch),imgs,step)</span><br><span class="line">        step = step+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>





<h1 id="网络基本骨架的搭建"><a href="#网络基本骨架的搭建" class="headerlink" title="网络基本骨架的搭建"></a>网络基本骨架的搭建</h1><p>关于神经网络的工具一般都在torch.nn<Neural network>里面</Neural></p>
<p>Containers—&gt;神经网络的骨架、结构，常用Module模块，为所有神经网络提供一个基本的骨架，所搭建的神经网络必须从torch.nn.Module类继承而来。其中有个forward函数，它是call方法的实现，在所有继承了torch.nn.Module类的子类中都要重写，是前向传播，比较重要，类似于call方法直接调用类作为方法，它的作用是输入通过forward变为输出</p>
<p>Module的使用代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#这种方法也可以初始化，但是我不知道区别在哪</span></span><br><span class="line">    <span class="comment">#def __init__(self):</span></span><br><span class="line">        <span class="comment">#super(Model, self).__init__()</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,<span class="built_in">input</span></span>):</span><br><span class="line">        output = <span class="built_in">input</span> +<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line">x = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line"><span class="comment"># 把x放到神经网络中</span></span><br><span class="line">output = model(x)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<p>Sequential的目的可以让神经网络代码压缩在一段代码中，过程连续。</p>
<p>sequential实例代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear, Sequential</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line">        <span class="comment"># self.conv1 = Conv2d(3,32,5,padding=2)</span></span><br><span class="line">        <span class="comment"># self.maxpool1 = MaxPool2d(2)</span></span><br><span class="line">        <span class="comment"># self.conv2 = Conv2d(32,32,5,padding=2)</span></span><br><span class="line">        <span class="comment"># self.maxpool2 = MaxPool2d(2)</span></span><br><span class="line">        <span class="comment"># self.conv3 = Conv2d(32,64,5,padding=2)</span></span><br><span class="line">        <span class="comment"># self.maxpool3 = MaxPool2d(2)</span></span><br><span class="line">        <span class="comment"># self.flatten = Flatten()</span></span><br><span class="line">        <span class="comment"># self.linear1 = Linear(1024,64)</span></span><br><span class="line">        <span class="comment"># self.linear2 = Linear(64,10)</span></span><br><span class="line"></span><br><span class="line">        self.module1 = Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"><span class="comment"># 检验网络参数是否正确的话，可以一步步写forward 然后运行查看output.shape</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="comment"># x = self.conv1(x)</span></span><br><span class="line">        <span class="comment"># x = self.maxpool1(x)</span></span><br><span class="line">        <span class="comment"># x = self.conv2(x)</span></span><br><span class="line">        <span class="comment"># x = self.maxpool2(x)</span></span><br><span class="line">        <span class="comment"># x = self.conv3(x)</span></span><br><span class="line">        <span class="comment"># x = self.maxpool3(x)</span></span><br><span class="line">        <span class="comment"># x = self.flatten(x)</span></span><br><span class="line">        <span class="comment"># x = self.linear1(x)</span></span><br><span class="line">        <span class="comment"># x = self.linear2(x)</span></span><br><span class="line"></span><br><span class="line">        x = self.module1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">cnn = CNN()</span><br><span class="line"><span class="built_in">print</span>(cnn)</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.ones((<span class="number">64</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">output = cnn(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line">writer.add_graph(cnn,<span class="built_in">input</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>



<h1 id="Covolution-Layers—-gt-卷积层"><a href="#Covolution-Layers—-gt-卷积层" class="headerlink" title="Covolution Layers—&gt;卷积层"></a>Covolution Layers—&gt;卷积层</h1><p>卷积核随机初始化，网络训练的就是卷积核</p>
<p>卷积操作内部具体实现&lt;实践用不到&gt;：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="comment"># 数据类型转换</span></span><br><span class="line"><span class="built_in">input</span> = torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line">                      [<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">5</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">                      [<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">kernel = torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">                       [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">                       [<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>]])</span><br><span class="line"><span class="comment">#调整尺寸，由于cov2d的input需要四位张量</span></span><br><span class="line"><span class="built_in">input</span> = torch.reshape(<span class="built_in">input</span>,(<span class="number">1</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">kernel = torch.reshape(kernel,(<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.shape)</span><br><span class="line"><span class="built_in">print</span>(kernel.shape)</span><br><span class="line"></span><br><span class="line">output = F.conv2d(<span class="built_in">input</span>,kernel,stride=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"></span><br><span class="line">output2 = F.conv2d(<span class="built_in">input</span>,kernel,stride=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(output2)</span><br><span class="line"></span><br><span class="line">output3 = F.conv2d(<span class="built_in">input</span>,kernel,stride=<span class="number">1</span>,padding=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(output3)</span><br></pre></td></tr></table></figure>

<p>代码示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">dataloader = DataLoader(dataset,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(NN, self).__init__()</span><br><span class="line">        self.conv1 = Conv2d(in_channels=<span class="number">3</span>,out_channels=<span class="number">6</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nn = NN()</span><br><span class="line"><span class="built_in">print</span>(nn)</span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,targets = data</span><br><span class="line">    output = nn(imgs)</span><br><span class="line">    <span class="built_in">print</span>(imgs.shape)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br><span class="line">    <span class="comment">#torch.Size([64, 3, 32, 32])</span></span><br><span class="line">    writer.add_images(<span class="string">&quot;input&quot;</span>,imgs,step)</span><br><span class="line">    <span class="comment">#torch.Size([64, 6, 30, 30]) 会报错，因为彩色图像为3个channel，6个channel不知道怎么显示</span></span><br><span class="line"></span><br><span class="line">    output = torch.reshape(output,(-<span class="number">1</span>,<span class="number">3</span>,<span class="number">30</span>,<span class="number">30</span>))<span class="comment">#设置-1，会根据数据自动调整</span></span><br><span class="line">    writer.add_images(<span class="string">&quot;output&quot;</span>,output,step)</span><br><span class="line">    step = step + <span class="number">1</span></span><br></pre></td></tr></table></figure>

<h1 id="Pooling-Layers—-gt-池化层"><a href="#Pooling-Layers—-gt-池化层" class="headerlink" title="Pooling Layers—&gt;池化层"></a>Pooling Layers—&gt;池化层</h1><p>最大池化目的：保留输入的特征，同时把参数量减少</p>
<p>代码示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> MaxPool2d</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line">                     [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line">                     [<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                     [<span class="number">5</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">                     [<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>]],dtype=torch.float32)<span class="comment">#其中数字转化为浮点数，编程浮点数的tensor类型</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.reshape(<span class="built_in">input</span>,(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">maxpool</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(maxpool, self).__init__()</span><br><span class="line">        self.maxpool1 = MaxPool2d(kernel_size=<span class="number">3</span>,ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,<span class="built_in">input</span></span>):</span><br><span class="line">        output = self.maxpool1(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mp = maxpool()</span><br><span class="line"><span class="comment"># output = mp(input)</span></span><br><span class="line"><span class="comment"># print(output)</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,targets = data</span><br><span class="line">    writer.add_images(<span class="string">&quot;input&quot;</span>,imgs,step)</span><br><span class="line">    output = mp(imgs)<span class="comment">#得到的图像依然是三维的</span></span><br><span class="line">    writer.add_images(<span class="string">&quot;output&quot;</span>,output,step)</span><br><span class="line">    step=step+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<h1 id="非线性激活"><a href="#非线性激活" class="headerlink" title="非线性激活"></a>非线性激活</h1><p>RELU，当input＞0时，赋值为input原来值，当input＜0时，赋值为0，输入只有N—&gt;batch_size；Sigmoid，也只是输入N。</p>
<p>ReLU的实例代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> ReLU</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.tensor([[<span class="number">1</span>,-<span class="number">0.5</span>],</span><br><span class="line">                     [-<span class="number">1</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="built_in">input</span> = torch.reshape(<span class="built_in">input</span>,(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RELU</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(RELU, self).__init__()</span><br><span class="line">        self.relu = ReLU()<span class="comment">#inplace这个参数如果是True就在原值上进行改变，如果为False原值不变，返回改变后的值</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,<span class="built_in">input</span></span>):</span><br><span class="line">        output = self.relu(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">relu = RELU()</span><br><span class="line">output = relu(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<p>Sigmoid的实例代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> ReLU, Sigmoid</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SigMoid</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SigMoid, self).__init__()</span><br><span class="line">        self.sigmoid = Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,<span class="built_in">input</span></span>):</span><br><span class="line">        output = self.sigmoid(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">sigmoid = SigMoid()</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader = DataLoader(dataset,batch_size = <span class="number">64</span>)</span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,targets = data</span><br><span class="line">    writer.add_images(<span class="string">&quot;input&quot;</span>,imgs,step)</span><br><span class="line">    output=sigmoid(imgs)</span><br><span class="line">    writer.add_images(<span class="string">&quot;output&quot;</span>,output,step)</span><br><span class="line">    step=step+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p>Padding Layers—&gt;填充层，用的不多，在卷积里能达到同样的效果</p>
<p>Normalization Layers—&gt;标准化层，用的不多</p>
<h1 id="Linear-Layers—-gt-全连接层"><a href="#Linear-Layers—-gt-全连接层" class="headerlink" title="Linear Layers—&gt;全连接层"></a>Linear Layers—&gt;全连接层</h1><p>Linear代码示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Linear</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset =torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader= DataLoader(dataset,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LINEAR</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(LINEAR, self).__init__()</span><br><span class="line">        self.linear = Linear(<span class="number">196608</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,<span class="built_in">input</span></span>):</span><br><span class="line">        output = self.linear(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">linear = LINEAR()</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,target = data</span><br><span class="line">    <span class="built_in">print</span>(imgs.shape)</span><br><span class="line">    <span class="comment"># output = torch.reshape(imgs,(1,1,1,-1))</span></span><br><span class="line">    output = torch.flatten(imgs)<span class="comment">#扁平化处理</span></span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br><span class="line">    output = linear(output)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br></pre></td></tr></table></figure>



<p>Loss Function：loss就是输出值与实际的误差值，越小越好，是神经网络训练的依据。可以计算实际输出和目标之间的差距，为我们更新输出提供一定的依据(反向传播)。</p>
<ul>
<li>CrossEntropyLoss，交叉熵，分类问题中有C个类别。</li>
</ul>
<p>各种loss函数的使用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> L1Loss, MSELoss</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实际默认的数据就是float，这是因为我们创建tensor的时候没有加小数</span></span><br><span class="line">inputs = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],dtype=torch.float32)</span><br><span class="line">targets = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">inputs = torch.reshape(inputs,(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line">targets = torch.reshape(targets,(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">loss = L1Loss()<span class="comment">#默认是取平均差值，可以选择取加值</span></span><br><span class="line">result = loss(inputs,targets)</span><br><span class="line"><span class="built_in">print</span>(result)<span class="comment">#tensor(0.6667)</span></span><br><span class="line"></span><br><span class="line">loss_mse = MSELoss()<span class="comment">#取平均平方差</span></span><br><span class="line">result_mse = loss_mse(inputs,targets)</span><br><span class="line"><span class="built_in">print</span>(result_mse)<span class="comment">#tensor(1.3333)</span></span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.3</span>])</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line">y = torch.tensor([<span class="number">1</span>])</span><br><span class="line">x = torch.reshape(x,(<span class="number">1</span>,<span class="number">3</span>))<span class="comment">#一张图，三个分类</span></span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line">loss_cross = nn.CrossEntropyLoss()</span><br><span class="line">result_cross = loss_cross(x,y)</span><br><span class="line"><span class="built_in">print</span>(result_cross)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear, Sequential</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>,train = <span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(dataset,batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line">        self.module1 = Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.module1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line">cnn = CNN()</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    <span class="comment">#看outputs和targets长什么样，看选择什么样的损失函数</span></span><br><span class="line">    imgs,targets = data</span><br><span class="line">    output = cnn(imgs)</span><br><span class="line">    <span class="comment"># print(output)</span></span><br><span class="line">    <span class="comment"># print(targets)</span></span><br><span class="line">    <span class="comment"># 反向传播，求导，需要选择合适的优化器</span></span><br><span class="line">    result_loss = loss(output,targets)</span><br><span class="line">    <span class="comment"># print(result_loss)</span></span><br><span class="line">    <span class="comment">#得到反向传播要更新参数对应的梯度</span></span><br><span class="line">    result_loss.backward()</span><br></pre></td></tr></table></figure>

<p>加上参数调优之后的整个网络：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear, Sequential</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>,train = <span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(dataset,batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line">        self.module1 = Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.module1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 交叉熵损失函数</span></span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line">cnn = CNN()</span><br><span class="line"><span class="comment"># 优化器,第一个参数是模型的参数</span></span><br><span class="line">optim = torch.optim.SGD(cnn.parameters(),lr= <span class="number">0.01</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">        <span class="comment"># 看outputs和targets长什么样，看选择什么样的损失函数</span></span><br><span class="line">        imgs,targets = data</span><br><span class="line">        output = cnn(imgs)</span><br><span class="line">        <span class="comment"># 计算loss</span></span><br><span class="line">        result_loss = loss(output,targets)</span><br><span class="line">        <span class="comment"># 把上一个循环中每个参数对应的梯度清零</span></span><br><span class="line">        optim.zero_grad()</span><br><span class="line">        <span class="comment"># 反向传播，计算更新参数对应的梯度</span></span><br><span class="line">        result_loss.backward()</span><br><span class="line">        <span class="comment"># 参数调优</span></span><br><span class="line">        optim.step()</span><br><span class="line">        running_loss = running_loss + result_loss</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(running_loss)</span><br></pre></td></tr></table></figure>



<h1 id="使用网络模型调参"><a href="#使用网络模型调参" class="headerlink" title="使用网络模型调参"></a>使用网络模型调参</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># train_data = torchvision.datasets.ImageNet(&quot;./dataset_ImageNet&quot;,split=&#x27;train&#x27;,transform=torchvision.transforms.ToTensor())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 当为false的时候，加载网络模型——&gt;默认参数，可以将pretrained=False改为weight=none；为True的时候需要从网络中下载每一个参数pretrained=True改成weight=default</span></span><br><span class="line">vgg16_false = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line">vgg16_true = torchvision.models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(vgg16_true)</span></span><br><span class="line"></span><br><span class="line">train_data = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对VGG-16 True进行调参修改,加到最后</span></span><br><span class="line">vgg16_true.add_module(<span class="string">&#x27;add_linear&#x27;</span>,nn.Linear(<span class="number">1000</span>,<span class="number">10</span>))</span><br><span class="line"><span class="comment"># print(vgg16_true)</span></span><br><span class="line"><span class="comment">#加到相应标签下</span></span><br><span class="line">vgg16_true.classifier.add_module(<span class="string">&#x27;add_linear&#x27;</span>,nn.Linear(<span class="number">1000</span>,<span class="number">10</span>))</span><br><span class="line"><span class="comment"># print(vgg16_true)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(vgg16_false)</span></span><br><span class="line"><span class="comment">#对某一个步骤进行修改</span></span><br><span class="line">vgg16_false.classifier[<span class="number">6</span>] =nn.Linear(<span class="number">4096</span>,<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(vgg16_false)</span><br></pre></td></tr></table></figure>



<h1 id="网络模型的保存与读取"><a href="#网络模型的保存与读取" class="headerlink" title="网络模型的保存与读取"></a>网络模型的保存与读取</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 保存方式1,保存网络模型的结构和参数</span></span><br><span class="line"><span class="comment"># 在别的文件使用方法 model = torch.load(&quot;vgg16_method1.pth&quot;)</span></span><br><span class="line">torch.save(vgg16,<span class="string">&quot;vgg16_method1.pth&quot;</span>)</span><br><span class="line"><span class="comment"># 方式一陷阱</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">cnn</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(cnn, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>,<span class="number">64</span>,kernel_size=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">Cnn = cnn()</span><br><span class="line">torch.save(cnn,<span class="string">&quot;Cnn_method1.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载会报错，需要将模型的定义一并放到引用文件中，或者from model_save import *也可以</span></span><br><span class="line">model = torch.load(<span class="string">&quot;Cnn_method1.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存方式2(推荐)</span></span><br><span class="line"><span class="comment"># 将vgg16的参数保存成字典型</span></span><br><span class="line"><span class="comment"># 在别的文件中使用方法 model = torch.load(&quot;vgg16_method2.pth&quot;)</span></span><br><span class="line">torch.save(vgg16.state_dict(),<span class="string">&quot;vgg16_method2.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用方法</span></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line">vgg16.load_state_dict(torch.load(<span class="string">&quot;vgg16_method2.pth&quot;</span>))</span><br></pre></td></tr></table></figure>



<h1 id="完整的模型训练套路"><a href="#完整的模型训练套路" class="headerlink" title="完整的模型训练套路"></a>完整的模型训练套路</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备数据集</span></span><br><span class="line">train_data = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_data = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># length 长度</span></span><br><span class="line">train_data_size = <span class="built_in">len</span>(train_data)</span><br><span class="line">test_data_size = <span class="built_in">len</span>(test_data)</span><br><span class="line"><span class="comment"># 字符串格式化写法</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练数据集的长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_data_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练数据集的长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(test_data_size))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用DataLoader加载数据集</span></span><br><span class="line">train_dataloader = DataLoader(train_data,batch_size=<span class="number">64</span>)</span><br><span class="line">test_dataloader = DataLoader(test_data,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建网络模型</span></span><br><span class="line">cnn = CNN()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建损失函数</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br><span class="line">optimizer = torch.optim.SGD(cnn.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置训练网络的一些参数</span></span><br><span class="line"><span class="comment"># 记录训练的次数</span></span><br><span class="line">total_train_step = <span class="number">0</span></span><br><span class="line"><span class="comment"># 记录测试的次数</span></span><br><span class="line">total_test_step = <span class="number">0</span></span><br><span class="line"><span class="comment"># 训练的轮数</span></span><br><span class="line">epoch = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加tensorboard</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;---------第&#123;&#125;轮训练开始---------&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 训练步骤开始</span></span><br><span class="line">    <span class="comment"># 设置成训练模式，与测试模式一样，只有当网络中有Dropout层、BatchNorm层等的时候才发挥作用</span></span><br><span class="line">    cnn.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs,targets = data</span><br><span class="line">        outputs = cnn(imgs)</span><br><span class="line">        loss = loss_fn(outputs,targets)</span><br><span class="line">        <span class="comment"># 优化器优化模型</span></span><br><span class="line">        <span class="comment"># 梯度清零</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># 参数优化</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        total_train_step=total_train_step+<span class="number">1</span></span><br><span class="line">        <span class="comment"># 加上item()会将tensor值转化为真实的数字，都可以</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;训练次数：&#123;&#125;，Loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_train_step,loss.item()))</span><br><span class="line">            writer.add_scalar(<span class="string">&quot;train_loss&quot;</span>,loss.item(),total_train_step)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 测试步骤开始</span></span><br><span class="line">    <span class="comment"># 设置成测试模式</span></span><br><span class="line">    cnn.<span class="built_in">eval</span>()</span><br><span class="line">    total_test_loss = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 整体正确的个数</span></span><br><span class="line">    total_accuracy = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 没有梯度，方便调优</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs,targets = data</span><br><span class="line">            outputs = cnn(imgs)</span><br><span class="line">            loss = loss_fn(outputs,targets)</span><br><span class="line">            total_test_loss = total_test_loss+loss</span><br><span class="line">            accuracy = (outputs.argmax(<span class="number">1</span>) == targets).<span class="built_in">sum</span>()</span><br><span class="line">            total_accuracy = total_accuracy + accuracy</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;整体测试集上的Loss：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_test_loss))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;整体测试集上的正确率：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_accuracy/test_data_size))</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;test_accuracy&quot;</span>,total_accuracy/test_data_size,total_test_step)</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;test_loss&quot;</span>,total_test_loss,total_test_step)</span><br><span class="line">    total_test_step = total_test_step+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># torch.save(cnn,&quot;cnn_&#123;&#125;.pth&quot;.format(i))</span></span><br><span class="line">    <span class="comment"># print(&quot;模型已保存&quot;)</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p>上述的准确率计算的说明：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">outputs = torch.tensor([[<span class="number">0.1</span>,<span class="number">0.2</span>],</span><br><span class="line">                       [<span class="number">0.3</span>,<span class="number">0.4</span>]])</span><br><span class="line"><span class="comment"># 参数为1的话从左往右看，0的话从上往下看</span></span><br><span class="line"><span class="built_in">print</span>(outputs.argmax(<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 看到预测的分类是哪个</span></span><br><span class="line">preds = outputs.argmax(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 实际的分类是哪个</span></span><br><span class="line">targets = torch.tensor([<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line"><span class="comment"># 计算出对应位置相等的个数</span></span><br><span class="line"><span class="built_in">print</span>((preds == targets).<span class="built_in">sum</span>())</span><br></pre></td></tr></table></figure>

<p>代码的CNN模型&lt;未调参&gt;：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建神经网络</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line">        self.model=nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>,<span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>,<span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">            x = self.model(x)</span><br><span class="line">            <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主函数用来debug，查看参数等</span></span><br><span class="line"><span class="comment"># if __name__ == &#x27;__main__&#x27;:</span></span><br><span class="line"><span class="comment">#     cnn =CNN()</span></span><br><span class="line"><span class="comment">#     input = torch.ones(64,3,32,32)</span></span><br><span class="line"><span class="comment">#     output = cnn(input)</span></span><br><span class="line"><span class="comment">#     print(output.shape)</span></span><br></pre></td></tr></table></figure>



<h1 id="如何使用GPU来训练"><a href="#如何使用GPU来训练" class="headerlink" title="如何使用GPU来训练"></a>如何使用GPU来训练</h1><p>第一种方式：需要网络模型、数据（输入，输出）、损失函数，调用<code>.cuda()</code>返回即可</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="comment"># from model import *</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="comment"># 准备数据集,数据集没有cuda方法</span></span><br><span class="line">train_data = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_data = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># length 长度</span></span><br><span class="line">train_data_size = <span class="built_in">len</span>(train_data)</span><br><span class="line">test_data_size = <span class="built_in">len</span>(test_data)</span><br><span class="line"><span class="comment"># 字符串格式化写法</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练数据集的长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_data_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练数据集的长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(test_data_size))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用DataLoader加载数据集</span></span><br><span class="line">train_dataloader = DataLoader(train_data,batch_size=<span class="number">64</span>)</span><br><span class="line">test_dataloader = DataLoader(test_data,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建网络模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line">        self.model=nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>,<span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>,<span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">            x = self.model(x)</span><br><span class="line">            <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">cnn = CNN()</span><br><span class="line"><span class="comment"># 网络模型转移到cuda上面,判断cuda是否可用</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    cnn = cnn.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建损失函数</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 损失函数的cuda</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    loss_fn = loss_fn.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br><span class="line">optimizer = torch.optim.SGD(cnn.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置训练网络的一些参数</span></span><br><span class="line"><span class="comment"># 记录训练的次数</span></span><br><span class="line">total_train_step = <span class="number">0</span></span><br><span class="line"><span class="comment"># 记录测试的次数</span></span><br><span class="line">total_test_step = <span class="number">0</span></span><br><span class="line"><span class="comment"># 训练的轮数</span></span><br><span class="line">epoch = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加tensorboard</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"></span><br><span class="line">start_time = time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;---------第&#123;&#125;轮训练开始---------&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 训练步骤开始</span></span><br><span class="line">    <span class="comment"># 设置成训练模式，与测试模式一样，只有当网络中有Dropout层、BatchNorm层等的时候才发挥作用</span></span><br><span class="line">    cnn.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs,targets = data</span><br><span class="line">        <span class="comment"># 对输入数据进行cuda</span></span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">            imgs = imgs.cuda()</span><br><span class="line">            targets = targets.cuda()</span><br><span class="line">        outputs = cnn(imgs)</span><br><span class="line">        loss = loss_fn(outputs,targets)</span><br><span class="line">        <span class="comment"># 优化器优化模型</span></span><br><span class="line">        <span class="comment"># 梯度清零</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># 参数优化</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        total_train_step = total_train_step+<span class="number">1</span></span><br><span class="line">        <span class="comment"># 加上item()会将tensor值转化为真实的数字，都可以</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            end_time = time.time()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;耗时：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(end_time-start_time))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;训练次数：&#123;&#125;，Loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_train_step,loss.item()))</span><br><span class="line">            writer.add_scalar(<span class="string">&quot;train_loss&quot;</span>,loss.item(),total_train_step)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 测试步骤开始</span></span><br><span class="line">    <span class="comment"># 设置成测试模式</span></span><br><span class="line">    cnn.<span class="built_in">eval</span>()</span><br><span class="line">    total_test_loss = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 整体正确的个数</span></span><br><span class="line">    total_accuracy = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 没有梯度，方便调优</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs,targets = data</span><br><span class="line">            <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">                imgs = imgs.cuda()</span><br><span class="line">                targets = targets.cuda()</span><br><span class="line">            outputs = cnn(imgs)</span><br><span class="line">            loss = loss_fn(outputs,targets)</span><br><span class="line">            total_test_loss = total_test_loss+loss</span><br><span class="line">            accuracy = (outputs.argmax(<span class="number">1</span>) == targets).<span class="built_in">sum</span>()</span><br><span class="line">            total_accuracy = total_accuracy + accuracy</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;整体测试集上的Loss：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_test_loss))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;整体测试集上的正确率：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_accuracy/test_data_size))</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;test_accuracy&quot;</span>,total_accuracy/test_data_size,total_test_step)</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;test_loss&quot;</span>,total_test_loss,total_test_step)</span><br><span class="line">    total_test_step = total_test_step+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># torch.save(cnn,&quot;cnn_&#123;&#125;.pth&quot;.format(i))</span></span><br><span class="line">    <span class="comment"># print(&quot;模型已保存&quot;)</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>



<p>第二种GPU训练方式：需要网络模型、数据（输入，输出）、损失函数，调用<code>.to(device)</code>，这个<code>divcie = torch.device(&quot;cpu&quot;)</code>也可以是<code>device = torch.device(&quot;cuda&quot;)</code>，电脑有多个显卡的话，可以指定<code>device = torch.device(&quot;cuda:n&quot;)</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="comment"># from model import *</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="comment"># 定义训练设备，如果cuda可用，采用GPU，不可用的话采用CPU</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_avaliable() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">train_data = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_data = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># length 长度</span></span><br><span class="line">train_data_size = <span class="built_in">len</span>(train_data)</span><br><span class="line">test_data_size = <span class="built_in">len</span>(test_data)</span><br><span class="line"><span class="comment"># 字符串格式化写法</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练数据集的长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_data_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练数据集的长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(test_data_size))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用DataLoader加载数据集</span></span><br><span class="line">train_dataloader = DataLoader(train_data,batch_size=<span class="number">64</span>)</span><br><span class="line">test_dataloader = DataLoader(test_data,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建网络模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line">        self.model=nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>,<span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>,<span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">            x = self.model(x)</span><br><span class="line">            <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">cnn = CNN()</span><br><span class="line"><span class="comment"># 网络模型转移到cuda上面,判断cuda是否可用</span></span><br><span class="line"></span><br><span class="line">cnn = cnn.cuda()</span><br><span class="line">cnn = cnn.to(device) <span class="comment"># 也可以不用赋值，直接cnn.to(device)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建损失函数</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 损失函数的cuda</span></span><br><span class="line"></span><br><span class="line">loss_fn = loss_fn.cuda()</span><br><span class="line">loss_fn = loss_fn.to(device)</span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br><span class="line">optimizer = torch.optim.SGD(cnn.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置训练网络的一些参数</span></span><br><span class="line"><span class="comment"># 记录训练的次数</span></span><br><span class="line">total_train_step = <span class="number">0</span></span><br><span class="line"><span class="comment"># 记录测试的次数</span></span><br><span class="line">total_test_step = <span class="number">0</span></span><br><span class="line"><span class="comment"># 训练的轮数</span></span><br><span class="line">epoch = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加tensorboard</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"></span><br><span class="line">start_time = time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;---------第&#123;&#125;轮训练开始---------&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 训练步骤开始</span></span><br><span class="line">    <span class="comment"># 设置成训练模式，与测试模式一样，只有当网络中有Dropout层、BatchNorm层等的时候才发挥作用</span></span><br><span class="line">    cnn.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs,targets = data</span><br><span class="line">        <span class="comment"># 对输入数据调用硬件</span></span><br><span class="line">        imgs = imgs.to(device)</span><br><span class="line">        targets = targets.to(device)</span><br><span class="line">        outputs = cnn(imgs)</span><br><span class="line">        loss = loss_fn(outputs,targets)</span><br><span class="line">        <span class="comment"># 优化器优化模型</span></span><br><span class="line">        <span class="comment"># 梯度清零</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># 参数优化</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        total_train_step = total_train_step+<span class="number">1</span></span><br><span class="line">        <span class="comment"># 加上item()会将tensor值转化为真实的数字，都可以</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            end_time = time.time()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;耗时：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(end_time-start_time))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;训练次数：&#123;&#125;，Loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_train_step,loss.item()))</span><br><span class="line">            writer.add_scalar(<span class="string">&quot;train_loss&quot;</span>,loss.item(),total_train_step)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 测试步骤开始</span></span><br><span class="line">    <span class="comment"># 设置成测试模式</span></span><br><span class="line">    cnn.<span class="built_in">eval</span>()</span><br><span class="line">    total_test_loss = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 整体正确的个数</span></span><br><span class="line">    total_accuracy = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 没有梯度，方便调优</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs,targets = data</span><br><span class="line">            imgs = imgs.to(device)</span><br><span class="line">            targets = targets.to(device)</span><br><span class="line">            outputs = cnn(imgs)</span><br><span class="line">            loss = loss_fn(outputs,targets)</span><br><span class="line">            total_test_loss = total_test_loss+loss</span><br><span class="line">            accuracy = (outputs.argmax(<span class="number">1</span>) == targets).<span class="built_in">sum</span>()</span><br><span class="line">            total_accuracy = total_accuracy + accuracy</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;整体测试集上的Loss：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_test_loss))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;整体测试集上的正确率：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_accuracy/test_data_size))</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;test_accuracy&quot;</span>,total_accuracy/test_data_size,total_test_step)</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;test_loss&quot;</span>,total_test_loss,total_test_step)</span><br><span class="line">    total_test_step = total_test_step+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># torch.save(cnn,&quot;cnn_&#123;&#125;.pth&quot;.format(i))</span></span><br><span class="line">    <span class="comment"># print(&quot;模型已保存&quot;)</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>



<h1 id="完整的模型验证（测试，demo）套路"><a href="#完整的模型验证（测试，demo）套路" class="headerlink" title="完整的模型验证（测试，demo）套路"></a>完整的模型验证（测试，demo）套路</h1><p>核心是利用已经训练好的模型，然后给它提供输入。</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">image_path = <span class="string">&quot;./img/dog.jpg&quot;</span></span><br><span class="line">image = Image.<span class="built_in">open</span>(image_path)</span><br><span class="line"><span class="comment"># 因为png格式是4个通道，除了RGB三通道外，还有一个透明度通道</span></span><br><span class="line"><span class="comment"># 调用image = image.convert(&#x27;RGB&#x27;)，保留颜色通道，加上这一步之后，不管是png还是jpg图片都可以运行</span></span><br><span class="line">image = image.convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">transform = torchvision.transforms.Compose([torchvision.transforms.Resize((<span class="number">32</span>,<span class="number">32</span>)),</span><br><span class="line">                                            torchvision.transforms.ToTensor()])</span><br><span class="line">image = transform(image)</span><br><span class="line"><span class="built_in">print</span>(image.shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line">        self.model=nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>,<span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>,<span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">            x = self.model(x)</span><br><span class="line">            <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为train文件里面我没有保存模型，所以这里我是没法运行的，要先运行train文件</span></span><br><span class="line"><span class="comment"># 采用GPU训练的模型，在CPU加载的过程中，要映射到CPU上</span></span><br><span class="line">model = torch.load(<span class="string">&quot;cnn_9.pth&quot;</span>,map_location=torch.device(<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line"><span class="comment"># model的输入要是4维的</span></span><br><span class="line">torch.reshape(image,(<span class="number">1</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line"><span class="comment"># 记得写上</span></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    output = model(image)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(output.argmax(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>

</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://6jybuchiyu.github.io">洁莹不吃鱼</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://6jybuchiyu.github.io/2023/01/09/pytorch/">https://6jybuchiyu.github.io/2023/01/09/pytorch/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://6jybuchiyu.github.io" target="_blank">洁莹不吃鱼</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E6%A1%86%E6%9E%B6/">框架</a></div><div class="post_share"><div class="social-share" data-image="/./img/blogset/2.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/01/14/%E8%AE%A1%E7%BD%91/"><img class="prev-cover" src="/./img/blogset/2.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info"></div></div></a></div><div class="next-post pull-right"><a href="/2023/01/08/python/"><img class="next-cover" src="/./img/blogset/3.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">python</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/12/30/CNN/" title="CNN"><img class="cover" src="/./img/blogset/9.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-30</div><div class="title">CNN</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/./img/blogset/9.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">洁莹不吃鱼</div><div class="author-info__description">记录一方天地罢了</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">6</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/6jybuchiyu" target="_blank" title="GitHub"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:jybuchiyu@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://y.qq.com/n/ryqq/profile/like/song?uin=oi6koiSq7ecsov**" target="_blank" title="QQMusic"><i class="fa-solid fa-music"></i></a><a class="social-icon" href="https://space.bilibili.com/39143065" target="_blank" title="bilibili"><i class="fa-solid fa-tv"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%A4%E4%B8%AA%E9%87%8D%E8%A6%81%E5%87%BD%E6%95%B0"><span class="toc-number">1.</span> <span class="toc-text">两个重要函数</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="toc-number">2.</span> <span class="toc-text">加载数据</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#TensorBoard%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">3.</span> <span class="toc-text">TensorBoard的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#SummaryWriter%E7%B1%BB%E4%BD%BF%E7%94%A8"><span class="toc-number">3.1.</span> <span class="toc-text">SummaryWriter类使用</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Transforms%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">4.</span> <span class="toc-text">Transforms的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Transforms%E7%9A%84%E7%BB%93%E6%9E%84%E5%8F%8A%E7%94%A8%E6%B3%95"><span class="toc-number">4.1.</span> <span class="toc-text">Transforms的结构及用法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tensor%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">4.2.</span> <span class="toc-text">tensor数据类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84Transform"><span class="toc-number">4.3.</span> <span class="toc-text">常见的Transform</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B0%86dataset%E5%92%8Ctransform%E7%BB%93%E5%90%88%E5%88%B0%E4%B8%80%E8%B5%B7"><span class="toc-number">5.</span> <span class="toc-text">将dataset和transform结合到一起</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#dataloader"><span class="toc-number">6.</span> <span class="toc-text">dataloader</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E9%AA%A8%E6%9E%B6%E7%9A%84%E6%90%AD%E5%BB%BA"><span class="toc-number">7.</span> <span class="toc-text">网络基本骨架的搭建</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Covolution-Layers%E2%80%94-gt-%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">8.</span> <span class="toc-text">Covolution Layers—&gt;卷积层</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Pooling-Layers%E2%80%94-gt-%E6%B1%A0%E5%8C%96%E5%B1%82"><span class="toc-number">9.</span> <span class="toc-text">Pooling Layers—&gt;池化层</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BB"><span class="toc-number">10.</span> <span class="toc-text">非线性激活</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Linear-Layers%E2%80%94-gt-%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82"><span class="toc-number">11.</span> <span class="toc-text">Linear Layers—&gt;全连接层</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82"><span class="toc-number">12.</span> <span class="toc-text">使用网络模型调参</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%AF%BB%E5%8F%96"><span class="toc-number">13.</span> <span class="toc-text">网络模型的保存与读取</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%A5%97%E8%B7%AF"><span class="toc-number">14.</span> <span class="toc-text">完整的模型训练套路</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8GPU%E6%9D%A5%E8%AE%AD%E7%BB%83"><span class="toc-number">15.</span> <span class="toc-text">如何使用GPU来训练</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81%EF%BC%88%E6%B5%8B%E8%AF%95%EF%BC%8Cdemo%EF%BC%89%E5%A5%97%E8%B7%AF"><span class="toc-number">16.</span> <span class="toc-text">完整的模型验证（测试，demo）套路</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/01/14/%E8%AE%A1%E7%BD%91/" title="无题"><img src="/./img/blogset/2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/2023/01/14/%E8%AE%A1%E7%BD%91/" title="无题">无题</a><time datetime="2023-01-14T08:15:32.678Z" title="发表于 2023-01-14 16:15:32">2023-01-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/09/pytorch/" title="pytorch"><img src="/./img/blogset/2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="pytorch"/></a><div class="content"><a class="title" href="/2023/01/09/pytorch/" title="pytorch">pytorch</a><time datetime="2023-01-08T23:47:47.000Z" title="发表于 2023-01-09 07:47:47">2023-01-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/08/python/" title="python"><img src="/./img/blogset/3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="python"/></a><div class="content"><a class="title" href="/2023/01/08/python/" title="python">python</a><time datetime="2023-01-08T14:02:22.000Z" title="发表于 2023-01-08 22:02:22">2023-01-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/05/PCA%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/" title="PCA主成分分析"><img src="/./img/blogset/5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="PCA主成分分析"/></a><div class="content"><a class="title" href="/2023/01/05/PCA%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/" title="PCA主成分分析">PCA主成分分析</a><time datetime="2023-01-05T08:13:07.000Z" title="发表于 2023-01-05 16:13:07">2023-01-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/30/Action/" title="Action"><img src="/./img/blogset/1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Action"/></a><div class="content"><a class="title" href="/2022/12/30/Action/" title="Action">Action</a><time datetime="2022-12-30T06:08:46.000Z" title="发表于 2022-12-30 14:08:46">2022-12-30</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/./img/blogset/2.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By 洁莹不吃鱼</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>